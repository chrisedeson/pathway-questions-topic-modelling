{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4488c59",
   "metadata": {},
   "source": [
    "# BYU Pathway Questions Topic Modeling - Google Colab Edition\n",
    "\n",
    "This notebook analyzes student questions using AI-powered topic modeling with OpenAI embeddings and BERTopic.\n",
    "\n",
    "## üìã What you'll need:\n",
    "1. **OpenAI API Key** - Get one from [platform.openai.com](https://platform.openai.com)\n",
    "2. **Questions file** - A .txt file with one question per line\n",
    "3. **About 5-10 minutes** for analysis to complete\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072a058b",
   "metadata": {},
   "source": [
    "## üöÄ Step 1: Install Required Libraries\n",
    "\n",
    "Run this cell to install all necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d2cdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bertopic>=0.15.0 openai>=1.0.0 umap-learn>=0.5.0 hdbscan>=0.8.0 plotly>=5.0.0 scikit-learn>=1.0.0 pandas>=1.3.0 numpy>=1.21.0\n",
    "print(\"‚úÖ Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342a0cf4",
   "metadata": {},
   "source": [
    "## üì¶ Step 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d84f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Topic modeling libraries\n",
    "from bertopic import BERTopic\n",
    "from openai import OpenAI\n",
    "import umap.umap_ as umap\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Utilities\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import getpass\n",
    "\n",
    "# Try to import Google Colab utilities if available\n",
    "try:\n",
    "    from google.colab import files\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    print(\"‚úÖ Running in Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"‚úÖ Running in local environment\")\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4bf49e",
   "metadata": {},
   "source": [
    "## üîë Step 3: Configure OpenAI API Key\n",
    "\n",
    "Enter your OpenAI API key when prompted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5231306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get OpenAI API key securely\n",
    "print(\"üîë Please enter your OpenAI API key:\")\n",
    "print(\"   Get your key from: https://platform.openai.com/api-keys\")\n",
    "api_key = getpass.getpass(\"API Key: \")\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Test the API key\n",
    "try:\n",
    "    response = client.models.list()\n",
    "    print(\"‚úÖ API key is valid and working!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå API key error: {e}\")\n",
    "    print(\"Please check your API key and try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c954ce31",
   "metadata": {},
   "source": [
    "## üì§ Step 4: Upload Your Questions File\n",
    "\n",
    "Upload a .txt file with one question per line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7fc734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload or load questions file\n",
    "if IN_COLAB:\n",
    "    print(\"üì§ Please upload your questions file (.txt format, one question per line):\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    if uploaded:\n",
    "        filename = list(uploaded.keys())[0]\n",
    "        print(f\"\\nüìÅ Processing file: {filename}\")\n",
    "        \n",
    "        # Read questions\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "else:\n",
    "    # For local environments, use a file path or sample data\n",
    "    print(\"üíª Local environment detected.\")\n",
    "    print(\"Please ensure your questions file is in the same directory as this notebook.\")\n",
    "    filename = input(\"Enter the filename (e.g., 'questions.txt'): \").strip()\n",
    "    \n",
    "    if not filename:\n",
    "        # Use sample questions for demonstration\n",
    "        print(\"üéØ Using sample questions for demonstration...\")\n",
    "        content = \"\"\"How do I register for classes?\n",
    "What financial aid options are available?\n",
    "How do I access my transcripts?\n",
    "What are the graduation requirements?\n",
    "How do I contact my academic advisor?\n",
    "What is the refund policy?\n",
    "How do I change my major?\n",
    "What are the library hours?\n",
    "How do I access online resources?\n",
    "What technical requirements do I need?\"\"\"\n",
    "        filename = \"sample_questions.txt\"\n",
    "    else:\n",
    "        try:\n",
    "            with open(filename, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "        except FileNotFoundError:\n",
    "            print(f\"‚ùå File '{filename}' not found. Using sample questions instead.\")\n",
    "            content = \"\"\"How do I register for classes?\n",
    "What financial aid options are available?\n",
    "How do I access my transcripts?\n",
    "What are the graduation requirements?\n",
    "How do I contact my academic advisor?\"\"\"\n",
    "            filename = \"sample_questions.txt\"\n",
    "\n",
    "# Clean and process questions\n",
    "questions = [line.strip() for line in content.split('\\n') if line.strip()]\n",
    "questions = [q for q in questions if len(q) > 10]  # Remove very short questions\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(questions)} questions from {filename}\")\n",
    "\n",
    "# Show preview\n",
    "print(\"\\nüìñ First 5 questions:\")\n",
    "for i, q in enumerate(questions[:5], 1):\n",
    "    print(f\"{i}. {q}\")\n",
    "\n",
    "if len(questions) < 10:\n",
    "    print(\"‚ö†Ô∏è  Warning: Less than 10 questions detected. Consider adding more questions for better analysis.\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Ready to analyze {len(questions)} questions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c13e87c",
   "metadata": {},
   "source": [
    "## üß† Step 5: Run Topic Modeling Analysis\n",
    "\n",
    "This will take 5-10 minutes depending on the number of questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581fb3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Starting topic modeling analysis...\\n\")\n",
    "print(f\"üìä Analyzing {len(questions)} questions\")\n",
    "print(\"‚è≥ This will take several minutes...\\n\")\n",
    "\n",
    "# Configuration\n",
    "embedding_model = \"text-embedding-3-large\"\n",
    "chat_model = \"gpt-4o-mini\"\n",
    "min_cluster_size = min(5, max(2, len(questions) // 20))  # Adaptive cluster size\n",
    "batch_size = 100\n",
    "\n",
    "print(f\"üìã Configuration:\")\n",
    "print(f\"   ‚Ä¢ Embedding Model: {embedding_model}\")\n",
    "print(f\"   ‚Ä¢ Chat Model: {chat_model}\")\n",
    "print(f\"   ‚Ä¢ Min Cluster Size: {min_cluster_size}\")\n",
    "print(f\"   ‚Ä¢ Batch Size: {batch_size}\\n\")\n",
    "\n",
    "# Step 1: Generate embeddings with improved error handling\n",
    "print(\"üîÑ Step 1/4: Generating embeddings with OpenAI...\")\n",
    "embeddings = []\n",
    "failed_batches = []\n",
    "total_batches = (len(questions) - 1) // batch_size + 1\n",
    "\n",
    "for i in range(0, len(questions), batch_size):\n",
    "    batch = questions[i:i + batch_size]\n",
    "    batch_num = (i // batch_size) + 1\n",
    "    \n",
    "    print(f\"   Processing batch {batch_num}/{total_batches} ({len(batch)} questions)...\")\n",
    "    \n",
    "    try:\n",
    "        response = client.embeddings.create(\n",
    "            input=batch,\n",
    "            model=embedding_model\n",
    "        )\n",
    "        \n",
    "        batch_embeddings = [data.embedding for data in response.data]\n",
    "        embeddings.extend(batch_embeddings)\n",
    "        \n",
    "        # Progress update\n",
    "        if batch_num % 5 == 0:\n",
    "            print(f\"   ‚úÖ Processed {batch_num}/{total_batches} batches successfully\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error processing batch {batch_num}: {e}\")\n",
    "        failed_batches.append(batch_num)\n",
    "        # Continue processing remaining batches\n",
    "        continue\n",
    "\n",
    "if failed_batches:\n",
    "    print(f\"   ‚ö†Ô∏è Failed to process {len(failed_batches)} batches: {failed_batches}\")\n",
    "    print(f\"   ‚úÖ Successfully processed {len(embeddings)} questions\")\n",
    "else:\n",
    "    print(f\"   ‚úÖ All batches processed successfully!\")\n",
    "\n",
    "embeddings = np.array(embeddings)\n",
    "print(f\"‚úÖ Generated {len(embeddings)} embeddings (shape: {embeddings.shape})\\n\")\n",
    "\n",
    "# Validate embeddings before proceeding\n",
    "if len(embeddings) < len(questions) * 0.8:  # If we lost more than 20% of questions\n",
    "    print(\"‚ö†Ô∏è Warning: Significant number of questions failed embedding generation.\")\n",
    "    print(\"Consider retrying or checking your API key and quota.\")\n",
    "\n",
    "# Step 2: Dimensionality reduction and clustering\n",
    "print(\"üîÑ Step 2/4: Reducing dimensions and clustering...\")\n",
    "\n",
    "# UMAP for clustering (5D) - adaptive neighbors based on dataset size\n",
    "n_neighbors = min(15, max(5, len(questions) // 10))\n",
    "print(f\"   ‚Ä¢ UMAP dimensionality reduction (n_neighbors={n_neighbors})...\")\n",
    "\n",
    "umap_model = umap.UMAP(\n",
    "    n_neighbors=n_neighbors,\n",
    "    n_components=5,\n",
    "    random_state=42,\n",
    "    metric='cosine'\n",
    ")\n",
    "umap_embeddings = umap_model.fit_transform(embeddings)\n",
    "\n",
    "# HDBSCAN clustering with adaptive parameters\n",
    "print(f\"   ‚Ä¢ HDBSCAN clustering (min_cluster_size={min_cluster_size})...\")\n",
    "hdbscan_model = HDBSCAN(\n",
    "    min_cluster_size=min_cluster_size,\n",
    "    metric='euclidean',\n",
    "    cluster_selection_method='eom',\n",
    "    prediction_data=True  # Allows for predicting cluster membership of new points\n",
    ")\n",
    "cluster_labels = hdbscan_model.fit_predict(umap_embeddings)\n",
    "\n",
    "# Analyze clustering results\n",
    "n_clusters = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)\n",
    "n_noise = list(cluster_labels).count(-1)\n",
    "categorization_rate = (len(embeddings) - n_noise) / len(embeddings) * 100\n",
    "\n",
    "print(f\"‚úÖ Clustering Results:\")\n",
    "print(f\"   ‚Ä¢ Clusters found: {n_clusters}\")\n",
    "print(f\"   ‚Ä¢ Noise points: {n_noise} ({n_noise/len(embeddings)*100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Questions categorized: {categorization_rate:.1f}%\")\n",
    "\n",
    "# Provide feedback on clustering quality\n",
    "if categorization_rate < 50:\n",
    "    print(\"   ‚ö†Ô∏è Low categorization rate. Consider reducing min_cluster_size.\")\n",
    "elif categorization_rate > 90:\n",
    "    print(\"   ‚úÖ Excellent categorization rate!\")\n",
    "else:\n",
    "    print(\"   ‚úÖ Good clustering results!\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Step 3: Create BERTopic model\n",
    "print(\"üîÑ Step 3/4: Training BERTopic model...\")\n",
    "\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\", max_features=1000)\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=None,  # We provide embeddings directly\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "topics, probs = topic_model.fit_transform(questions[:len(embeddings)], embeddings)\n",
    "print(f\"‚úÖ BERTopic model trained successfully\")\n",
    "print(f\"   ‚Ä¢ Topic assignments created for {len(topics)} questions\\n\")\n",
    "\n",
    "# Step 4: Enhance topic labels with OpenAI\n",
    "print(\"üîÑ Step 4/4: Enhancing topic labels with AI...\")\n",
    "\n",
    "topic_info = topic_model.get_topic_info()\n",
    "enhanced_labels = {}\n",
    "failed_labels = []\n",
    "\n",
    "for topic_id in topic_info['Topic'].unique():\n",
    "    if topic_id == -1:  # Skip noise\n",
    "        enhanced_labels[topic_id] = \"Uncategorized\"\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        keywords = topic_model.get_topic(topic_id)[:10]\n",
    "        keyword_str = \", \".join([word for word, _ in keywords])\n",
    "        \n",
    "        print(f\"   ‚Ä¢ Labeling topic {topic_id} (keywords: {keyword_str[:50]}...)\")\n",
    "        \n",
    "        prompt = f\"\"\"Based on these keywords from student questions: {keyword_str}\n",
    "\n",
    "Create a clear, concise topic label (2-4 words) that describes the main theme.\n",
    "Focus on what students are asking about. Examples: \"Course Registration\", \"Financial Aid\", \"Technical Support\"\n",
    "\n",
    "Topic label:\"\"\"\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=chat_model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=20,\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        enhanced_labels[topic_id] = response.choices[0].message.content.strip().strip('\"')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Failed to label topic {topic_id}: {e}\")\n",
    "        failed_labels.append(topic_id)\n",
    "        enhanced_labels[topic_id] = f\"Topic {topic_id}\"\n",
    "\n",
    "if failed_labels:\n",
    "    print(f\"   ‚ö†Ô∏è Used default labels for {len(failed_labels)} topics: {failed_labels}\")\n",
    "\n",
    "print(\"\\n‚úÖ Topic labeling complete!\")\n",
    "print(\"üéâ Analysis finished! Preparing results...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfcbe99",
   "metadata": {},
   "source": [
    "## üìä Step 6: View Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88178fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results DataFrame with proper alignment\n",
    "# Handle case where some questions might have failed embedding generation\n",
    "processed_questions = questions[:len(embeddings)]  # Align with successful embeddings\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Question': processed_questions,\n",
    "    'Topic_ID': topics,\n",
    "    'Probability': probs,\n",
    "    'Topic_Name': [enhanced_labels.get(topic_id, f\"Topic {topic_id}\") for topic_id in topics]\n",
    "})\n",
    "\n",
    "# Add UMAP coordinates for visualization\n",
    "umap_viz = umap.UMAP(\n",
    "    n_neighbors=min(15, max(5, len(embeddings) // 10)), \n",
    "    n_components=2, \n",
    "    random_state=42, \n",
    "    metric='cosine'\n",
    ")\n",
    "viz_embeddings = umap_viz.fit_transform(embeddings)\n",
    "results_df['UMAP_X'] = viz_embeddings[:, 0]\n",
    "results_df['UMAP_Y'] = viz_embeddings[:, 1]\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"üìà ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìä Total Questions Processed: {len(results_df)}\")\n",
    "print(f\"üè∑Ô∏è  Topics Discovered: {len(results_df['Topic_Name'].unique())}\")\n",
    "\n",
    "# Calculate categorization stats\n",
    "categorized_count = len(results_df[results_df['Topic_ID'] != -1])\n",
    "uncategorized_count = len(results_df[results_df['Topic_ID'] == -1])\n",
    "categorization_rate = categorized_count / len(results_df) * 100\n",
    "\n",
    "print(f\"‚úÖ Questions Categorized: {categorized_count} ({categorization_rate:.1f}%)\")\n",
    "print(f\"‚ùì Uncategorized (Noise): {uncategorized_count} ({uncategorized_count/len(results_df)*100:.1f}%)\")\n",
    "print(f\"üéØ Average Confidence: {results_df['Probability'].mean():.2f}\")\n",
    "\n",
    "# Show if any questions were dropped due to embedding failures\n",
    "if len(processed_questions) < len(questions):\n",
    "    dropped_count = len(questions) - len(processed_questions)\n",
    "    print(f\"‚ö†Ô∏è  Questions Dropped (embedding failed): {dropped_count}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Show topics found\n",
    "topic_counts = results_df.groupby('Topic_Name').size().reset_index(name='Count')\n",
    "topic_counts = topic_counts.sort_values('Count', ascending=False)\n",
    "\n",
    "print(\"üèÜ TOP TOPICS DISCOVERED:\")\n",
    "print(\"-\" * 40)\n",
    "for _, row in topic_counts.head(10).iterrows():\n",
    "    percentage = (row['Count'] / len(results_df)) * 100\n",
    "    print(f\"üìå {row['Topic_Name']:<30} {row['Count']:>3} questions ({percentage:.1f}%)\")\n",
    "\n",
    "# Quality assessment\n",
    "print(f\"\\nüìä ANALYSIS QUALITY:\")\n",
    "print(f\"   ‚Ä¢ Cluster Count: {'Excellent' if 5 <= len(topic_counts) <= 20 else 'Good' if len(topic_counts) > 0 else 'Poor'}\")\n",
    "print(f\"   ‚Ä¢ Categorization: {'Excellent' if categorization_rate > 80 else 'Good' if categorization_rate > 60 else 'Fair'}\")\n",
    "print(f\"   ‚Ä¢ Data Coverage: {'Complete' if len(processed_questions) == len(questions) else f'{len(processed_questions)}/{len(questions)} processed'}\")\n",
    "\n",
    "print(\"\\n‚úÖ Results processed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5c7383",
   "metadata": {},
   "source": [
    "## üìä Step 7: Interactive Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e948c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic Distribution Bar Chart\n",
    "print(\"üìä Creating topic distribution chart...\")\n",
    "\n",
    "fig = px.bar(\n",
    "    topic_counts.head(15),\n",
    "    x='Count',\n",
    "    y='Topic_Name',\n",
    "    orientation='h',\n",
    "    title=f\"üìä Topic Distribution - Top 15 Topics ({len(questions)} questions total)\",\n",
    "    color='Count',\n",
    "    color_continuous_scale='Viridis',\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    showlegend=False,\n",
    "    yaxis_title=None,\n",
    "    xaxis_title=\"Number of Questions\",\n",
    "    title_x=0.5\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "print(\"‚úÖ Bar chart created!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6ee40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Scatter Plot\n",
    "print(\"üó∫Ô∏è Creating interactive question clusters map...\")\n",
    "\n",
    "# Filter out uncategorized for cleaner visualization\n",
    "categorized_df = results_df[results_df['Topic_ID'] != -1]\n",
    "\n",
    "fig = px.scatter(\n",
    "    categorized_df,\n",
    "    x='UMAP_X',\n",
    "    y='UMAP_Y',\n",
    "    color='Topic_Name',\n",
    "    hover_data={\n",
    "        'Question': True,\n",
    "        'Topic_Name': True,\n",
    "        'Probability': ':.2f',\n",
    "        'UMAP_X': False,\n",
    "        'UMAP_Y': False\n",
    "    },\n",
    "    title=f\"üó∫Ô∏è Question Clusters Map - {len(categorized_df)} Categorized Questions (Hover to see questions)\",\n",
    "    width=900,\n",
    "    height=700\n",
    ")\n",
    "\n",
    "# Customize hover template\n",
    "fig.update_traces(\n",
    "    hovertemplate='<b>%{hovertext}</b><br>' +\n",
    "                  'Topic: %{customdata[1]}<br>' +\n",
    "                  'Confidence: %{customdata[2]}<br>' +\n",
    "                  '<extra></extra>',\n",
    "    hovertext=[q[:100] + '...' if len(q) > 100 else q for q in categorized_df['Question']]\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    showlegend=True,\n",
    "    title_x=0.5,\n",
    "    legend=dict(\n",
    "        orientation=\"v\",\n",
    "        yanchor=\"top\",\n",
    "        y=1,\n",
    "        xanchor=\"left\",\n",
    "        x=1.01\n",
    "    ),\n",
    "    xaxis_title=\"UMAP Dimension 1\",\n",
    "    yaxis_title=\"UMAP Dimension 2\"\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "print(\"‚úÖ Scatter plot created! Hover over points to see individual questions.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0317595",
   "metadata": {},
   "source": [
    "## üîç Step 8: Explore Questions by Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e42b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive topic exploration\n",
    "print(\"üîç Explore questions by topic:\\n\")\n",
    "\n",
    "# Show available topics\n",
    "available_topics = sorted(results_df['Topic_Name'].unique().tolist())\n",
    "print(\"üìã Available topics:\")\n",
    "for i, topic in enumerate(available_topics, 1):\n",
    "    count = len(results_df[results_df['Topic_Name'] == topic])\n",
    "    print(f\"{i:2d}. {topic:<30} ({count} questions)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üí° To explore a specific topic, run the next cell and enter the topic number.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092b4b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic-specific question browser\n",
    "try:\n",
    "    topic_num = int(input(\"Enter topic number to explore (1-{}):\".format(len(available_topics))))\n",
    "    \n",
    "    if 1 <= topic_num <= len(available_topics):\n",
    "        selected_topic = available_topics[topic_num - 1]\n",
    "        topic_questions = results_df[results_df['Topic_Name'] == selected_topic]\n",
    "        \n",
    "        print(f\"\\nüè∑Ô∏è  TOPIC: {selected_topic}\")\n",
    "        print(f\"üìä {len(topic_questions)} questions in this topic\\n\")\n",
    "        \n",
    "        # Sort by confidence\n",
    "        topic_questions = topic_questions.sort_values('Probability', ascending=False)\n",
    "        \n",
    "        print(\"üìù Questions (sorted by confidence):\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        for i, (_, row) in enumerate(topic_questions.iterrows(), 1):\n",
    "            confidence = row['Probability']\n",
    "            question = row['Question']\n",
    "            \n",
    "            print(f\"{i:2d}. [{confidence:.2f}] {question}\")\n",
    "            \n",
    "            if i >= 20:  # Limit to first 20\n",
    "                remaining = len(topic_questions) - 20\n",
    "                if remaining > 0:\n",
    "                    print(f\"\\n... and {remaining} more questions in this topic\")\n",
    "                break\n",
    "    else:\n",
    "        print(\"‚ùå Invalid topic number!\")\n",
    "        \n",
    "except ValueError:\n",
    "    print(\"‚ùå Please enter a valid number!\")\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚èπÔ∏è  Exploration cancelled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd60a9e",
   "metadata": {},
   "source": [
    "## üíæ Step 9: Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17fc77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results to CSV\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "csv_filename = f\"pathway_questions_analysis_{timestamp}.csv\"\n",
    "\n",
    "# Export full results\n",
    "results_df.to_csv(csv_filename, index=False)\n",
    "print(f\"‚úÖ Full analysis exported to: {csv_filename}\")\n",
    "\n",
    "# Create summary report\n",
    "summary_filename = f\"analysis_summary_{timestamp}.txt\"\n",
    "with open(summary_filename, 'w') as f:\n",
    "    f.write(\"BYU PATHWAY QUESTIONS ANALYSIS SUMMARY\\n\")\n",
    "    f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "    f.write(f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"Total Questions: {len(results_df)}\\n\")\n",
    "    f.write(f\"Topics Found: {len(results_df['Topic_Name'].unique())}\\n\")\n",
    "    f.write(f\"Questions Categorized: {len(results_df[results_df['Topic_ID'] != -1])} ({len(results_df[results_df['Topic_ID'] != -1])/len(results_df)*100:.1f}%)\\n\")\n",
    "    f.write(f\"Average Confidence: {results_df['Probability'].mean():.2f}\\n\\n\")\n",
    "    \n",
    "    f.write(\"TOP TOPICS:\\n\")\n",
    "    f.write(\"-\" * 30 + \"\\n\")\n",
    "    for _, row in topic_counts.head(15).iterrows():\n",
    "        f.write(f\"{row['Topic_Name']:<30} {row['Count']:>3} questions\\n\")\n",
    "\n",
    "print(f\"‚úÖ Summary report saved to: {summary_filename}\")\n",
    "\n",
    "# Download files\n",
    "print(\"\\nüì• Downloading files...\")\n",
    "files.download(csv_filename)\n",
    "files.download(summary_filename)\n",
    "\n",
    "print(\"\\nüéâ Analysis complete! Your files have been downloaded.\")\n",
    "print(\"\\nüìã What you received:\")\n",
    "print(f\"   ‚Ä¢ {csv_filename} - Full analysis with all questions, topics, and confidence scores\")\n",
    "print(f\"   ‚Ä¢ {summary_filename} - Summary report with key insights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e6e5cc",
   "metadata": {},
   "source": [
    "## üéØ Analysis Complete!\n",
    "\n",
    "### What you accomplished:\n",
    "- ‚úÖ **Processed** your questions using state-of-the-art AI embeddings\n",
    "- ‚úÖ **Discovered** meaningful topic clusters automatically\n",
    "- ‚úÖ **Generated** AI-enhanced topic labels\n",
    "- ‚úÖ **Created** interactive visualizations\n",
    "- ‚úÖ **Exported** results for further analysis\n",
    "\n",
    "### Next Steps:\n",
    "1. **Review** the downloaded CSV file with all results\n",
    "2. **Share** insights with your team using the summary report\n",
    "3. **Use** the topic clusters to improve student support\n",
    "4. **Re-run** this analysis with new questions as they come in\n",
    "\n",
    "---\n",
    "\n",
    "### üîÑ Want to analyze more questions?\n",
    "Simply restart this notebook and upload a new file!\n",
    "\n",
    "### üåê Need a persistent dashboard?\n",
    "Consider using the **Streamlit web app** version for ongoing analysis and team sharing.\n",
    "\n",
    "---\n",
    "\n",
    "*Built with ‚ù§Ô∏è for BYU Pathway ‚Ä¢ Powered by OpenAI, BERTopic, and Google Colab*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
