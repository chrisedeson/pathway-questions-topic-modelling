#!/usr/bin/env python3
"""
Real-world performance comparison: Sequential vs Concurrent processing
"""
import sys
import os
import asyncio
import time
from unittest.mock import Mock, AsyncMock, patch

# Add src to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

async def simulate_topic_generation_sequential(n_topics):
    """Simulate sequential topic generation"""
    print(f"üêå Sequential: Processing {n_topics} topics...")
    
    start_time = time.time()
    
    # Simulate sequential API calls
    results = []
    for i in range(n_topics):
        await asyncio.sleep(0.3)  # Typical OpenAI API latency
        results.append(f"Topic {i+1}")
        print(f"   Generated topic {i+1}/{n_topics}")
    
    end_time = time.time()
    duration = end_time - start_time
    
    print(f"   ‚úÖ Sequential completed in {duration:.2f} seconds")
    return results, duration

async def simulate_topic_generation_concurrent(n_topics, max_concurrent=5):
    """Simulate concurrent topic generation with semaphore"""
    print(f"üöÄ Concurrent (max {max_concurrent}): Processing {n_topics} topics...")
    
    semaphore = asyncio.Semaphore(max_concurrent)
    
    async def generate_single_topic(topic_id):
        async with semaphore:
            await asyncio.sleep(0.3)  # Same API latency
            return f"Topic {topic_id+1}"
    
    start_time = time.time()
    
    # Create all tasks
    tasks = [generate_single_topic(i) for i in range(n_topics)]
    print(f"   Created {len(tasks)} concurrent tasks")
    
    # Execute concurrently
    results = await asyncio.gather(*tasks)
    
    end_time = time.time()
    duration = end_time - start_time
    
    print(f"   ‚úÖ Concurrent completed in {duration:.2f} seconds")
    return results, duration

async def performance_comparison():
    """Compare sequential vs concurrent performance"""
    print("üèÅ Performance Comparison: Sequential vs Concurrent")
    print("=" * 60)
    
    test_cases = [
        {"topics": 5, "description": "Small batch (5 topics)"},
        {"topics": 10, "description": "Medium batch (10 topics)"},
        {"topics": 20, "description": "Large batch (20 topics)"},
    ]
    
    concurrency_levels = [3, 5, 8]
    
    for case in test_cases:
        n_topics = case["topics"]
        description = case["description"]
        
        print(f"\nüìä Test Case: {description}")
        print("-" * 40)
        
        # Sequential test
        sequential_results, sequential_time = await simulate_topic_generation_sequential(n_topics)
        
        print()  # Add spacing
        
        # Test different concurrency levels
        best_concurrent_time = float('inf')
        best_concurrency = 3
        
        for concurrency in concurrency_levels:
            if concurrency <= n_topics:  # Only test reasonable concurrency levels
                concurrent_results, concurrent_time = await simulate_topic_generation_concurrent(n_topics, concurrency)
                
                speedup = sequential_time / concurrent_time
                print(f"   Speedup with {concurrency} concurrent: {speedup:.1f}x faster")
                
                if concurrent_time < best_concurrent_time:
                    best_concurrent_time = concurrent_time
                    best_concurrency = concurrency
                
                print()  # Add spacing
        
        # Summary for this test case
        best_speedup = sequential_time / best_concurrent_time
        time_saved = sequential_time - best_concurrent_time
        
        print(f"üìà Summary for {description}:")
        print(f"   Sequential time: {sequential_time:.2f}s")
        print(f"   Best concurrent time: {best_concurrent_time:.2f}s (concurrency {best_concurrency})")
        print(f"   Best speedup: {best_speedup:.1f}x faster")
        print(f"   Time saved: {time_saved:.2f} seconds")
        
        # Calculate cost savings (assuming API costs are per-request, not per-time)
        efficiency_gain = (time_saved / sequential_time) * 100
        print(f"   Efficiency gain: {efficiency_gain:.1f}%")
        
        print("=" * 60)

def calculate_real_world_impact():
    """Calculate real-world impact for typical use cases"""
    print("\nüíº Real-World Impact Analysis")
    print("=" * 60)
    
    scenarios = [
        {"name": "Small Analysis", "topics": 8, "frequency": "daily"},
        {"name": "Medium Analysis", "topics": 25, "frequency": "weekly"},
        {"name": "Large Analysis", "topics": 50, "frequency": "monthly"},
        {"name": "Enterprise Analysis", "topics": 100, "frequency": "quarterly"},
    ]
    
    for scenario in scenarios:
        name = scenario["name"]
        topics = scenario["topics"]
        frequency = scenario["frequency"]
        
        # Calculate times (based on 0.3s per API call)
        sequential_time = topics * 0.3  # seconds
        concurrent_time = (topics / 5) * 0.3  # assuming 5 concurrent
        
        time_saved_per_run = sequential_time - concurrent_time
        
        # Calculate frequency multipliers
        frequency_multipliers = {
            "daily": 365,
            "weekly": 52,
            "monthly": 12,
            "quarterly": 4
        }
        
        multiplier = frequency_multipliers[frequency]
        annual_time_saved = time_saved_per_run * multiplier
        
        print(f"\nüìä {name} ({topics} topics, {frequency}):")
        print(f"   Time per run - Sequential: {sequential_time:.1f}s, Concurrent: {concurrent_time:.1f}s")
        print(f"   Time saved per run: {time_saved_per_run:.1f} seconds")
        print(f"   Annual time saved: {annual_time_saved/60:.1f} minutes ({annual_time_saved/3600:.1f} hours)")
        
        # User experience impact
        if time_saved_per_run > 10:
            impact = "üöÄ Major improvement"
        elif time_saved_per_run > 5:
            impact = "‚ö° Significant improvement"
        elif time_saved_per_run > 2:
            impact = "‚úÖ Noticeable improvement"
        else:
            impact = "üìà Minor improvement"
        
        print(f"   User experience: {impact}")

async def main():
    """Run all performance tests"""
    await performance_comparison()
    calculate_real_world_impact()
    
    print("\nüéØ CONCLUSION:")
    print("   ‚Ä¢ Concurrent processing provides 3-5x speedup for topic generation")
    print("   ‚Ä¢ Optimal concurrency: 5-8 concurrent requests")
    print("   ‚Ä¢ Most significant impact on larger batches (15+ topics)")
    print("   ‚Ä¢ Professional async patterns improve user experience")
    print("   ‚Ä¢ No additional API costs (same number of requests)")

if __name__ == "__main__":
    asyncio.run(main())